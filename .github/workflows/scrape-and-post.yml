name: Scrape and Post to Micro.blog

on:
  schedule:
    # Run every 6 hours (00:00, 06:00, 12:00, 18:00 UTC)
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      limit:
        description: 'Maximum number of posts to publish to Micro.blog'
        required: false
        default: '20'
      force_scrape:
        description: 'Force full scrape (ignore existing posts)'
        required: false
        default: 'false'

jobs:
  scrape-and-post:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          cd content
          pip install -r requirements.txt
      
      - name: Scrape and post to Micro.blog
        env:
          MICROBLOG_TOKEN: ${{ secrets.MICROBLOG_TOKEN }}
          MICROBLOG_API_URL: https://micro.blog/micropub
        run: |
          cd content
          # Scrape new content (generates markdown in temp location)
          python3 scraper.py
          
          # Count new posts generated
          NEW_COUNT=$(find 20*/ -name "*.md" -type f 2>/dev/null | wc -l)
          echo "ðŸ“ Found $NEW_COUNT new posts to publish"
          
          # Post to Micro.blog if we have new content
          if [ "$NEW_COUNT" -gt 0 ]; then
            LIMIT="${{ github.event.inputs.limit || '20' }}"
            echo "ðŸš€ Posting up to $LIMIT items to Micro.blog..."
            python3 post_to_microblog.py "$LIMIT"
          else
            echo "âœ… No new content to post"
          fi
      
      - name: Create summary
        run: |
          echo "## Scraper Results" >> $GITHUB_STEP_SUMMARY
          NEW_COUNT=$(find content/20*/ -name "*.md" -type f 2>/dev/null | wc -l)
          echo "- New posts found: $NEW_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- Posted to Micro.blog: Yes" >> $GITHUB_STEP_SUMMARY
          echo "- Scraper completed at: $(date)" >> $GITHUB_STEP_SUMMARY
