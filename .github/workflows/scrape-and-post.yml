name: Scrape and Post to Micro.blog

on:
  schedule:
    # Run every 6 hours (00:00, 06:00, 12:00, 18:00 UTC)
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      limit:
        description: 'Maximum number of posts to publish to Micro.blog'
        required: false
        default: '20'
      force_scrape:
        description: 'Force full scrape (ignore existing posts)'
        required: false
        default: 'false'

jobs:
  scrape-and-post:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Allow pushing tracking file updates
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          cd scraper
          pip install -r requirements.txt
      
      - name: Scrape and post to Micro.blog
        env:
          MICROBLOG_TOKEN: ${{ secrets.MICROBLOG_TOKEN }}
          MICROBLOG_MP_DESTINATION: ${{ secrets.MICROBLOG_MP_DESTINATION }}
          MICROBLOG_API_URL: https://micro.blog/micropub
        run: |
          cd scraper
          echo "ðŸ” Running scraper..."
          python3 scraper.py
          
          echo ""
          echo "ðŸ“Š Counting generated posts..."
          total_posts=$(find ../content/[0-9][0-9][0-9][0-9] -name "*.md" 2>/dev/null | wc -l)
          echo "Total posts: $total_posts"
          
          echo ""
          echo "ðŸ“¤ Posting to Micro.blog..."
          python3 post_to_microblog.py 5
      
      - name: Commit tracking file
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Add tracking file if it exists
          if [ -f scraper/scraped_posts.json ]; then
            git add scraper/scraped_posts.json
          fi
          
          # Commit if there are changes
          if ! git diff --staged --quiet; then
            git commit -m "Update scraped post IDs [skip ci]"
            git push
            echo "âœ… Tracking file updated"
          else
            echo "â„¹ï¸  No changes to commit"
          fi
      
      - name: Wait for Micro.blog to publish
        run: |
          echo "â³ Waiting 5 minutes for Micro.blog to rebuild site..."
          sleep 300
      
      - name: Validate RSS feed
        id: validate_feed
        continue-on-error: true
        run: |
          COMMIT_SHA=$(git rev-parse --short HEAD)
          FEED_URL="https://adobedigest.com/feed.xml?v=${COMMIT_SHA}"
          VALIDATOR_URL="https://validator.w3.org/feed/check.cgi?url=$(echo -n "$FEED_URL" | jq -sRr @uri)"
          
          echo "ðŸ” Validating RSS feed..."
          echo "Feed URL: $FEED_URL"
          echo "Validator: $VALIDATOR_URL"
          
          # Fetch the feed and check if it's valid XML
          if curl -sSf "$FEED_URL" | xmllint --noout - 2>/dev/null; then
            echo "âœ… Feed is valid XML"
            echo "valid=true" >> $GITHUB_OUTPUT
          else
            echo "âŒ Feed has XML errors"
            echo "valid=false" >> $GITHUB_OUTPUT
            exit 1
          fi
      
      - name: Create summary
        if: always()
        run: |
          echo "## Scraper Results" >> $GITHUB_STEP_SUMMARY
          NEW_COUNT=$(find content/20*/ -name "*.md" -type f 2>/dev/null | wc -l)
          echo "- New posts found: $NEW_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- Posted to Micro.blog: Yes" >> $GITHUB_STEP_SUMMARY
          echo "- Scraper completed at: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## RSS Feed Validation" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.validate_feed.outputs.valid }}" = "true" ]; then
            echo "- âœ… Feed is valid" >> $GITHUB_STEP_SUMMARY
          else
            echo "- âŒ Feed validation failed" >> $GITHUB_STEP_SUMMARY
          fi
          COMMIT_SHA=$(git rev-parse --short HEAD)
          FEED_URL="https://adobedigest.com/feed.xml?v=${COMMIT_SHA}"
          VALIDATOR_URL="https://validator.w3.org/feed/check.cgi?url=$(echo -n "$FEED_URL" | jq -sRr @uri)"
          echo "- [Check W3C Validator]($VALIDATOR_URL)" >> $GITHUB_STEP_SUMMARY
