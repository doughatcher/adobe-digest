name: Scrape and Post to Micro.blog

on:
  schedule:
    # Run every 6 hours (00:00, 06:00, 12:00, 18:00 UTC)
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      limit:
        description: 'Maximum number of posts to publish to Micro.blog'
        required: false
        default: '20'
      force_scrape:
        description: 'Force full scrape (ignore existing posts)'
        required: false
        default: 'false'

jobs:
  scrape-and-post:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          cd content
          pip install -r requirements.txt
      
      - name: Scrape and post to Micro.blog
        env:
          MICROBLOG_TOKEN: ${{ secrets.MICROBLOG_TOKEN }}
          MICROBLOG_MP_DESTINATION: ${{ secrets.MICROBLOG_MP_DESTINATION }}
          MICROBLOG_API_URL: https://micro.blog/micropub
        run: |
          cd content
          echo "ðŸ” Running scraper..."
          python3 scraper.py
          
          echo ""
          echo "ðŸ“Š Counting generated posts..."
          total_posts=$(find [0-9][0-9][0-9][0-9] -name "*.md" 2>/dev/null | wc -l)
          echo "Total posts: $total_posts"
          
          echo ""
          echo "ðŸ“¤ Posting to Micro.blog..."
          python3 post_to_microblog.py 5
      
      - name: Commit tracking file
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          cd content
          if [ -f scraped_posts.json ]; then
            git add scraped_posts.json
            git diff --staged --quiet || git commit -m "Update scraped post IDs [skip ci]"
            git push
            echo "âœ… Tracking file updated"
          else
            echo "â„¹ï¸  No tracking file to commit"
          fi
      
      - name: Create summary
        run: |
          echo "## Scraper Results" >> $GITHUB_STEP_SUMMARY
          NEW_COUNT=$(find content/20*/ -name "*.md" -type f 2>/dev/null | wc -l)
          echo "- New posts found: $NEW_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- Posted to Micro.blog: Yes" >> $GITHUB_STEP_SUMMARY
          echo "- Scraper completed at: $(date)" >> $GITHUB_STEP_SUMMARY
